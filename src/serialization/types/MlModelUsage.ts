/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as serializers from "../index";
import * as Vellum from "../../api/index";
import * as core from "../../core";

export const MlModelUsage: core.serialization.ObjectSchema<serializers.MlModelUsage.Raw, Vellum.MlModelUsage> =
    core.serialization.object({
        outputTokenCount: core.serialization.property(
            "output_token_count",
            core.serialization.number().optionalNullable(),
        ),
        inputTokenCount: core.serialization.property(
            "input_token_count",
            core.serialization.number().optionalNullable(),
        ),
        inputCharCount: core.serialization.property("input_char_count", core.serialization.number().optionalNullable()),
        outputCharCount: core.serialization.property(
            "output_char_count",
            core.serialization.number().optionalNullable(),
        ),
        computeNanos: core.serialization.property("compute_nanos", core.serialization.number().optionalNullable()),
        cacheCreationInputTokens: core.serialization.property(
            "cache_creation_input_tokens",
            core.serialization.number().optionalNullable(),
        ),
        cacheReadInputTokens: core.serialization.property(
            "cache_read_input_tokens",
            core.serialization.number().optionalNullable(),
        ),
    });

export declare namespace MlModelUsage {
    export interface Raw {
        output_token_count?: (number | null) | null;
        input_token_count?: (number | null) | null;
        input_char_count?: (number | null) | null;
        output_char_count?: (number | null) | null;
        compute_nanos?: (number | null) | null;
        cache_creation_input_tokens?: (number | null) | null;
        cache_read_input_tokens?: (number | null) | null;
    }
}
