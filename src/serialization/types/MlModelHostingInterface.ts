/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as serializers from "../index";
import * as Vellum from "../../api/index";
import * as core from "../../core";

export const MlModelHostingInterface: core.serialization.Schema<
    serializers.MlModelHostingInterface.Raw,
    Vellum.MlModelHostingInterface
> = core.serialization.enum_([
    "ANTHROPIC",
    "AWS_BEDROCK",
    "AZURE_AI_FOUNDRY",
    "AZURE_OPENAI",
    "BASETEN",
    "CEREBRAS",
    "COHERE",
    "CUSTOM",
    "DEEP_SEEK",
    "FIREWORKS_AI",
    "GOOGLE",
    "GOOGLE_VERTEX_AI",
    "GROQ",
    "HUGGINGFACE",
    "IBM_WATSONX",
    "MISTRAL_AI",
    "MOSAICML",
    "MYSTIC",
    "NVIDIA",
    "OPENAI",
    "OPEN_ROUTER",
    "OPENPIPE",
    "PERPLEXITY",
    "PYQ",
    "REPLICATE",
    "SAMBANOVA",
    "TOGETHER_AI",
    "X_AI",
    "FASTWEB",
    "SWISSCOM",
]);

export declare namespace MlModelHostingInterface {
    export type Raw =
        | "ANTHROPIC"
        | "AWS_BEDROCK"
        | "AZURE_AI_FOUNDRY"
        | "AZURE_OPENAI"
        | "BASETEN"
        | "CEREBRAS"
        | "COHERE"
        | "CUSTOM"
        | "DEEP_SEEK"
        | "FIREWORKS_AI"
        | "GOOGLE"
        | "GOOGLE_VERTEX_AI"
        | "GROQ"
        | "HUGGINGFACE"
        | "IBM_WATSONX"
        | "MISTRAL_AI"
        | "MOSAICML"
        | "MYSTIC"
        | "NVIDIA"
        | "OPENAI"
        | "OPEN_ROUTER"
        | "OPENPIPE"
        | "PERPLEXITY"
        | "PYQ"
        | "REPLICATE"
        | "SAMBANOVA"
        | "TOGETHER_AI"
        | "X_AI"
        | "FASTWEB"
        | "SWISSCOM";
}
