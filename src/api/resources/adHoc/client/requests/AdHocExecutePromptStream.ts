/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as Vellum from "../../../../index";

/**
 * @example
 *     {
 *         mlModel: "ml_model",
 *         inputValues: [{
 *                 key: "key",
 *                 type: "STRING",
 *                 value: "value"
 *             }],
 *         inputVariables: [{
 *                 id: "id",
 *                 key: "key",
 *                 type: "STRING"
 *             }],
 *         parameters: {},
 *         blocks: [{
 *                 blockType: "JINJA",
 *                 template: "template"
 *             }]
 *     }
 */
export interface AdHocExecutePromptStream {
    mlModel: string;
    inputValues: Vellum.PromptRequestInput[];
    inputVariables: Vellum.VellumVariable[];
    parameters: Vellum.PromptParameters;
    settings?: Vellum.PromptSettings | null;
    blocks: Vellum.PromptBlock[];
    functions?: Vellum.FunctionDefinition[] | null;
    expandMeta?: Vellum.AdHocExpandMeta | null;
}
